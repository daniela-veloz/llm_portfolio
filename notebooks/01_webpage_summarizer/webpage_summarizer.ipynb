{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ðŸŒ WebPage Summarizer\n\nAn intelligent web content summarization tool that extracts and condenses webpage information using advanced AI models.\n\n## ðŸ“‹ Overview\n\nThis project creates concise, structured summaries of web content by leveraging state-of-the-art language models and robust web scraping techniques. The tool supports both cloud-based and local AI models, including OpenAI's GPT-4o-mini and the open-source GPT-OSS:20B model through Ollama, providing flexibility for different deployment scenarios. Perfect for quickly understanding lengthy articles, blog posts, or documentation.\n\n## âœ¨ Key Features\n\n- **ðŸ¤– Dual AI Models**: Powered by OpenAI's `gpt-4o-mini` and open-source `gpt-oss:20b` through Ollama for high-quality text summarization\n- **ðŸ”“ Local & Cloud Options**: Choose between cloud-based OpenAI models or run models locally with Ollama\n- **ðŸ•·ï¸ Advanced Web Scraping**: Uses Selenium to handle both static and dynamic JavaScript-rendered websites\n- **ðŸ“ Markdown Output**: Generates clean, formatted summaries in Markdown for easy reading and sharing\n- **ðŸŽ¯ Focused Processing**: Efficiently processes individual webpage URLs without crawling entire sites\n- **âš¡ Multi-Tool Integration**: Combines multiple libraries for robust and reliable content extraction\n\n## ðŸ› ï¸ Technology Stack\n\n| Component | Technology | Purpose |\n|-----------|------------|---------|\n| **AI Models** | OpenAI GPT-4o-mini, GPT-OSS:20B | Content summarization |\n| **Web Scraping** | Selenium WebDriver | Dynamic content extraction |\n| **HTML Parsing** | BeautifulSoup | Static content processing |\n| **HTTP Requests** | Python Requests | Basic web requests |\n| **AI Integration** | OpenAI API, Ollama | Model access and inference |\n| **Local AI Runtime** | Ollama | Local model execution |\n| **Language** | Python | Core development |\n\n## ðŸš€ Installation Requirements\n\n### Ollama Setup\nTo use the GPT-OSS:20B model locally, you need to install Ollama:\n\n1. **Install Ollama**: Visit [ollama.com](https://ollama.com) and download for your platform\n2. **Pull the model**: After installation, run:\n   ```bash\n   ollama pull gpt-oss:20b\n   ```\n3. **Start Ollama service**: The service should start automatically, or run:\n   ```bash\n   ollama serve\n   ```\n\n### Python Dependencies\nInstall required Python packages:\n```bash\npip install selenium beautifulsoup4 webdriver-manager openai requests python-dotenv\n```\n\n## ðŸŽ¯ Project Scope\n\n- âœ… **Single URL Processing**: Focuses on individual webpage content\n- âœ… **Content Extraction**: Handles both static and dynamic web content\n- âœ… **AI Summarization**: Generates intelligent, contextual summaries\n- âœ… **Structured Output**: Provides clean Markdown formatting\n- âœ… **Local & Cloud AI**: Supports both local Ollama and cloud OpenAI models\n- âŒ **Site Crawling**: Does not process entire websites or multiple pages\n\n## ðŸ† Skill Level\n\n**Beginner-Friendly** - Perfect for developers learning:\n- Web scraping fundamentals\n- AI model integration\n- API consumption\n- Local AI deployment with Ollama\n- Content processing pipelines\n\n## ðŸš€ Use Cases\n\n- **ðŸ“° News Article Summaries**: Quickly digest lengthy news articles\n- **ðŸ“š Research Papers**: Extract key points from academic content\n- **ðŸ“– Documentation**: Summarize technical documentation\n- **ðŸ›ï¸ Product Reviews**: Condense detailed product information\n- **ðŸ’¼ Business Reports**: Extract insights from corporate content\n\n## ðŸ’¡ Benefits\n\n- **â° Time-Saving**: Reduces reading time by 70-80%\n- **ðŸŽ¯ Focus Enhancement**: Highlights key information and insights\n- **ðŸ“± Accessibility**: Markdown format works across all platforms\n- **ðŸ”„ Consistency**: Standardized summary format for all content\n- **ðŸ¤ Shareability**: Easy to share and collaborate on summaries\n- **ðŸ”’ Privacy Options**: Local processing with Ollama for sensitive content\n\n---\n\n*This project demonstrates practical application of AI, web scraping, and content processing technologies with both cloud and local deployment options.*",
   "id": "c37ebaa1071ec36f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Environment Setup",
   "id": "9c6c2ebc731b9925"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T19:27:32.020508Z",
     "start_time": "2025-08-06T19:27:31.893472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import site\n",
    "!uv pip install selenium beautifulsoup4 webdriver-manager"
   ],
   "id": "5ca157aaa38d0e7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2mUsing Python 3.12.11 environment at: /Users/daniela_veloz/Workspace/llm_portfolio/.venv\u001B[0m\r\n",
      "\u001B[2mAudited \u001B[1m3 packages\u001B[0m \u001B[2min 3ms\u001B[0m\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T19:27:32.030992Z",
     "start_time": "2025-08-06T19:27:32.029443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===========================\n",
    "# System & Environment\n",
    "# ===========================\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display"
   ],
   "id": "613e3e793a3e0599",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Web Scraping Module",
   "id": "843998359b1338c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T19:27:32.045139Z",
     "start_time": "2025-08-06T19:27:32.039836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
    "\n",
    "class WebUrlCrawler:\n",
    "    def __init__(self, headless=True, timeout=10):\n",
    "        self.timeout = timeout\n",
    "        self.driver = None\n",
    "        self.headless = headless\n",
    "\n",
    "    def _setup_driver(self):\n",
    "        chrome_options = Options()\n",
    "        if self.headless:\n",
    "            chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(\"--no-sandbox\")\n",
    "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "\n",
    "        try:\n",
    "            self.driver = webdriver.Chrome(options=chrome_options)\n",
    "            self.driver.set_page_load_timeout(self.timeout)\n",
    "        except WebDriverException as e:\n",
    "            raise Exception(f\"Failed to initialize Chrome driver: {e}\")\n",
    "\n",
    "    def _extract_main_content(self, html):\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # Remove unwanted elements\n",
    "        unwanted_tags = ['script', 'style', 'img', 'input', 'button', 'nav', 'footer', 'header']\n",
    "        for tag in unwanted_tags:\n",
    "            for element in soup.find_all(tag):\n",
    "                element.decompose()\n",
    "\n",
    "        # Try to find main content containers in order of preference\n",
    "        content_selectors = [\n",
    "            'main',\n",
    "            'article',\n",
    "            '[role=\"main\"]',\n",
    "            '.content',\n",
    "            '#content',\n",
    "            '.main-content',\n",
    "            '#main-content'\n",
    "        ]\n",
    "\n",
    "        for selector in content_selectors:\n",
    "            content_element = soup.select_one(selector)\n",
    "            if content_element:\n",
    "                return content_element.get_text(strip=True, separator='\\n')\n",
    "\n",
    "        # Fallback to body if no main content container found\n",
    "        body = soup.find('body')\n",
    "        if body:\n",
    "            return body.get_text(strip=True, separator='\\n')\n",
    "\n",
    "        return soup.get_text(strip=True, separator='\\n')\n",
    "\n",
    "    def crawl(self, url):\n",
    "        if not self.driver:\n",
    "            self._setup_driver()\n",
    "\n",
    "        try:\n",
    "            self.driver.get(url)\n",
    "\n",
    "            WebDriverWait(self.driver, self.timeout).until(\n",
    "                EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "            )\n",
    "\n",
    "            html_content = self.driver.page_source\n",
    "            main_content = self._extract_main_content(html_content)\n",
    "            return main_content\n",
    "\n",
    "        except TimeoutException:\n",
    "            raise Exception(f\"Timeout while loading {url}\")\n",
    "        except WebDriverException as e:\n",
    "            raise Exception(f\"Error crawling {url}: {e}\")\n",
    "\n",
    "    def close(self):\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "            self.driver = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.close()"
   ],
   "id": "be2ea096b1a04fac",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T19:27:32.054150Z",
     "start_time": "2025-08-06T19:27:32.050936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "class WebSite:\n",
    "    def __init__(self, url, title, body, links):\n",
    "        self.url = url\n",
    "        self.title = title\n",
    "        self.body = body\n",
    "        self.links = links\n",
    "\n",
    "class WebUrlCrawler:\n",
    "    # some websites need to use proper headers when fetching them\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "\n",
    "    def __init__(self, headless=True, timeout=10):\n",
    "        self.timeout = timeout\n",
    "        self.driver = None\n",
    "        self.headless = headless\n",
    "\n",
    "    def crawl(self, url) -> WebSite:\n",
    "        response = requests.get(url, headers=self.headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        title = soup.title.string if soup.title else \"No title found\"\n",
    "\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            body = soup.body.get_text(strip=True, separator='\\n')\n",
    "        else:\n",
    "            body = \"\"\n",
    "\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        links = [link for link in links if link]\n",
    "\n",
    "        return WebSite(url, title, body, links)\n",
    "\n"
   ],
   "id": "bbffb4482cf9fb",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LLM Client",
   "id": "bde63267e57cc786"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T19:27:32.062601Z",
     "start_time": "2025-08-06T19:27:32.060303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "class LLMClient:\n",
    "    def __init__(self, model, base_url=None):\n",
    "        self.model = model\n",
    "        if base_url:\n",
    "            self.openai = OpenAI(base_url=base_url, api_key=model)\n",
    "        else:\n",
    "            self.openai = OpenAI()\n",
    "\n",
    "    def generate_text(self, user_prompt, system_prompt=\"\") -> str:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "        response = self.openai.chat.completions.create(\n",
    "            model=MODEL_OPENAI,\n",
    "            messages= messages,\n",
    "        )\n",
    "        return response.choices[0].message.content"
   ],
   "id": "b811ef6a40e9cac5",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Summarization",
   "id": "3e867f7e6d2db52f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T19:27:32.071301Z",
     "start_time": "2025-08-06T19:27:32.069480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def summarize(url, llm_client):\n",
    "    crawler = WebUrlCrawler()\n",
    "    website = crawler.crawl(url)\n",
    "\n",
    "    system_prompt = \"\"\"You are a web page summarizer that analyzes the content of a provided web page and provides a short and relevant summary. You will also provide a TL;DR at the top. Return your response in markdown.\"\"\"\n",
    "    user_prompt = f\"\"\"You are looking at the website titled: {website.title}. The content if the website is as follows: {website.body}. \"\"\"\n",
    "\n",
    "    summary = llm_client.generate_text(system_prompt=system_prompt, user_prompt=user_prompt)\n",
    "    display(Markdown(summary))"
   ],
   "id": "66a370d90357edc2",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Summarization with gpt-4o-mini\n",
    "\n"
   ],
   "id": "9656a0a7ef274e96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Load open_api_key",
   "id": "d8746efa9815f43e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T19:27:32.081279Z",
     "start_time": "2025-08-06T19:27:32.078552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "   raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n",
    "\n",
    "print(\"âœ… API key loaded successfully!\")"
   ],
   "id": "49f454d0180b3900",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API key loaded successfully!\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Configure gpt-4o-mini client",
   "id": "ed60d127d13c0246"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T19:27:32.111059Z",
     "start_time": "2025-08-06T19:27:32.094356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_open_ai = \"gpt-4o-mini\"\n",
    "open_ai_llm_client = LLMClient(model=model_open_ai)"
   ],
   "id": "5153d5772cedff7f",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Example",
   "id": "c098df7191bcc838"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T19:27:40.139737Z",
     "start_time": "2025-08-06T19:27:32.117485Z"
    }
   },
   "cell_type": "code",
   "source": "summarize(\"https://en.wikipedia.org/wiki/Marie_Curie\", open_ai_llm_client)",
   "id": "4409a39d24fcdde3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "# TL;DR\nMarie Curie (1867â€“1934) was a pioneering Polish-French physicist and chemist who conducted groundbreaking research on radioactivity, earning the distinction of being the first woman to win a Nobel Prize and the only person to win Nobel Prizes in two different scientific fields. She discovered the elements polonium and radium, contributed significantly to the treatment of cancer, and created mobile X-ray units during World War I. Her legacy continues to influence science and gender equality in the scientific community.\n\n---\n\n### Summary\nMarie Curie, born Maria Salomea SkÅ‚odowska on November 7, 1867, in Warsaw, was a pioneering physicist and chemist. She moved to Paris for higher education, where she obtained degrees in physics and mathematics. Curie's research focused on radioactivity, a term she coined, leading to her seminal discovery of the radioactive elements polonium and radium alongside her husband Pierre Curie. \n\nShe made history by becoming the first woman to win a Nobel Prize in Physics in 1903 and the first person to win Nobel Prizes in two different scientific fields, receiving a second Nobel in Chemistry in 1911. Curie founded the Curie Institutes in Paris and Warsaw, vital centers for cancer research, and played a crucial role in medical advancements during World War I by developing mobile X-ray units.\n\nDespite facing significant societal and professional challenges as a woman in science, Curie maintained her integrity, rejecting opportunities for personal gain from her discoveries. She died on July 4, 1934, from aplastic anemia, likely due to prolonged exposure to radiation without adequate safety measures. Her contributions remain influential, embedding her legacy within the fabric of modern science and inspiring future generations of scientists."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Summarization with gpt-oss:20b",
   "id": "9206ad4fe37a09cf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Configure gpt-oss:20b client",
   "id": "76fe0218e6d9af8d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T19:27:40.179531Z",
     "start_time": "2025-08-06T19:27:40.156151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_open_ai = \"gpt-oss:20b\"\n",
    "gpt_oss_llm_client = LLMClient(model=model_open_ai)"
   ],
   "id": "576146eb9d7d0be2",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Example",
   "id": "26697afb69bf2bb7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T19:27:47.539301Z",
     "start_time": "2025-08-06T19:27:40.190619Z"
    }
   },
   "cell_type": "code",
   "source": "summarize(\"https://en.wikipedia.org/wiki/Marie_Curie\", gpt_oss_llm_client)",
   "id": "fc2c061a04bebb3b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "# TL;DR\nMarie Curie was a pioneering Polish-French scientist known for her groundbreaking work in radioactivity. She was the first woman to win a Nobel Prize, the first person to win it twice, and remains the only individual to win Nobel Prizes in two different scientific fieldsâ€”Physics and Chemistry. Curie's discoveries included the elements polonium and radium, and her research laid the groundwork for advances in medical treatment and nuclear science.\n\n---\n\n**Summary:**\n\nMarie Curie (1867-1934) was a notable physicist and chemist renowned for her pioneering research on radioactivity, a term she coined. Born Maria Salomea SkÅ‚odowska in Warsaw, she pursued her education in physics and mathematics at the University of Paris. Together with her husband, Pierre Curie, she discovered the radioactive elements polonium and radium. They were awarded the 1903 Nobel Prize in Physics alongside Henri Becquerel, making Curie the first woman to receive a Nobel Prize.\n\nFollowing Pierre's death in 1906, Curie became the first woman to hold a professorship at the University of Paris. She received a second Nobel Prize in Chemistry in 1911 for her continued work with radium and polonium. During World War I, she developed mobile radiography units to assist in battlefield medical care. \n\nCurieâ€™s dedication to science came at a personal cost, as she died of aplastic anemia likely caused by prolonged exposure to radiation. Her legacy continues with numerous institutions named in her honor, and she remains an icon for women in science, representing resilience and groundbreaking achievement."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 50
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
